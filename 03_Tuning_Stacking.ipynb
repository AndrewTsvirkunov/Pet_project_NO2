{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5599a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import LinearRegressiont\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, \\\n",
    "    mean_squared_log_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "import optuna\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RAND = 10\n",
    "N_FOLDS = 4\n",
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "629cbb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error train: 8.317\n",
      "Mean absolute error test: 8.347\n",
      "delta = 0.4 %\n",
      "Mean absolute error train: 0.497\n",
      "Mean absolute error test: 10.134\n",
      "delta = 95.1 %\n",
      "Mean absolute error train: 2.636\n",
      "Mean absolute error test: 8.258\n",
      "delta = 68.1 %\n",
      "Mean absolute error train: 5.710\n",
      "Mean absolute error test: 7.174\n",
      "delta = 20.4 %\n",
      "Mean absolute error train: 6.203\n",
      "Mean absolute error test: 7.121\n",
      "delta = 12.9 %\n",
      "Mean absolute error train: 5.770\n",
      "Mean absolute error test: 6.454\n",
      "delta = 10.6 %\n"
     ]
    }
   ],
   "source": [
    "%run C:\\Users\\main6\\OneDrive\\Документы\\jupyter\\Pet_pro\\notebooks\\02_Baseline.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5441157b",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053babf",
   "metadata": {},
   "source": [
    "## 5. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "406af93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial, X, y, N_FOLDS, random_state):\n",
    "    lgb_params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [2000]),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.028673457194108982]),        \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 1000, step=20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 15),\n",
    "        # борьба с переобучением\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 0, 100),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 0, 100),\n",
    "        'min_split_gain': trial.suggest_int('min_split_gain', 0, 20),\n",
    "        # доля объектов при обучении в дереве\n",
    "        'subsample': trial.suggest_float('bagging_fraction', 0.2, 1.0),\n",
    "        'subsample_freq': trial.suggest_categorical('bagging_freq', [1]),\n",
    "        # доля признаков при обучении в дереве\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
    "        # константы\n",
    "        'objective': trial.suggest_categorical('objective', ['mae']),\n",
    "        'random_state': trial.suggest_categorical('random_state', [random_state])\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=N_FOLDS, shuffle=True)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(\n",
    "           trial, metric='l1')\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  eval_metric='mae',\n",
    "                  callbacks=[pruning_callback],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = mean_absolute_error(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7cb513d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0af6e00243841849e5cd3d008e2d4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_lgbm = optuna.create_study(direction='minimize', study_name='LGB_00')\n",
    "func = lambda trial: objective_lgbm(\n",
    "    trial, X_train_ct, y_train_ct, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_lgbm.optimize(func, n_trials=5, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d67a444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 2000,\n",
       " 'learning_rate': 0.028673457194108982,\n",
       " 'num_leaves': 320,\n",
       " 'max_depth': 13,\n",
       " 'reg_alpha': 16,\n",
       " 'reg_lambda': 92,\n",
       " 'min_split_gain': 0,\n",
       " 'bagging_fraction': 0.7836616921026176,\n",
       " 'bagging_freq': 1,\n",
       " 'colsample_bytree': 0.8661455708217822,\n",
       " 'objective': 'mae',\n",
       " 'random_state': 10}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смотрим на параметры\n",
    "study_lgbm.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "35038246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7836616921026176, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7836616921026176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>MPE_%</th>\n",
       "      <th>MAPE_%</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression_baseline</td>\n",
       "      <td>8.347072</td>\n",
       "      <td>156.858720</td>\n",
       "      <td>12.524325</td>\n",
       "      <td>0.455343</td>\n",
       "      <td>0.451267</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>34.324438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisonTreeRegressor_baseline</td>\n",
       "      <td>10.133774</td>\n",
       "      <td>228.179589</td>\n",
       "      <td>15.105614</td>\n",
       "      <td>0.607437</td>\n",
       "      <td>0.201768</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>41.671629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor_baseline</td>\n",
       "      <td>8.258138</td>\n",
       "      <td>176.019952</td>\n",
       "      <td>13.267251</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.384236</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>33.958726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_baseline</td>\n",
       "      <td>7.173608</td>\n",
       "      <td>121.679612</td>\n",
       "      <td>11.030848</td>\n",
       "      <td>0.398242</td>\n",
       "      <td>0.574333</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>29.498972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_baseline</td>\n",
       "      <td>7.120787</td>\n",
       "      <td>122.711309</td>\n",
       "      <td>11.077514</td>\n",
       "      <td>0.393043</td>\n",
       "      <td>0.573203</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>29.304653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_baseline</td>\n",
       "      <td>6.453979</td>\n",
       "      <td>99.260909</td>\n",
       "      <td>9.962977</td>\n",
       "      <td>0.359331</td>\n",
       "      <td>0.654765</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>26.560497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_Optuna</td>\n",
       "      <td>6.443470</td>\n",
       "      <td>102.503548</td>\n",
       "      <td>10.124404</td>\n",
       "      <td>0.364783</td>\n",
       "      <td>0.643487</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>26.517247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model        MAE         MSE       RMSE     RMSLE  \\\n",
       "0       LinearRegression_baseline   8.347072  156.858720  12.524325  0.455343   \n",
       "0   DecisonTreeRegressor_baseline  10.133774  228.179589  15.105614  0.607437   \n",
       "0  RandomForestRegressor_baseline   8.258138  176.019952  13.267251  0.476677   \n",
       "0                XGBoost_baseline   7.173608  121.679612  11.030848  0.398242   \n",
       "0               LightGBM_baseline   7.120787  122.711309  11.077514  0.393043   \n",
       "0               CatBoost_baseline   6.453979   99.260909   9.962977  0.359331   \n",
       "0                 LightGBM_Optuna   6.443470  102.503548  10.124404  0.364783   \n",
       "\n",
       "   R2 adjusted  MPE_%  MAPE_%     WAPE_%  \n",
       "0     0.451267   -inf     inf  34.324438  \n",
       "0     0.201768   -inf     inf  41.671629  \n",
       "0     0.384236   -inf     inf  33.958726  \n",
       "0     0.574333   -inf     inf  29.498972  \n",
       "0     0.573203   -inf     inf  29.304653  \n",
       "0     0.654765   -inf     inf  26.560497  \n",
       "0     0.643487   -inf     inf  26.517247  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_opt = LGBMRegressor(**study_lgbm.best_params)\n",
    "lgbm_opt.fit(X_ct,\n",
    "             y_ct,\n",
    "             eval_metric='mae',\n",
    "             eval_set=eval_ct,\n",
    "             verbose=False,\n",
    "             early_stopping_rounds=100)\n",
    "\n",
    "y_pred = lgbm_opt.predict(X_test_ct)\n",
    "y_pred_exp = np.exp(y_pred) - 1\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics_regression(y_test=y_test_ct_exp,\n",
    "                           y_pred=y_pred_exp,\n",
    "                           X_test=X_test_ct,\n",
    "                           name='LightGBM_Optuna'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4081847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error train: 4.014\n",
      "Mean absolute error test: 6.443\n",
      "delta = 37.7 %\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(lgbm_opt,\n",
    "                  X_ct,\n",
    "                  y_ct_exp,\n",
    "                  X_test_ct,\n",
    "                  y_test_ct_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f139847f",
   "metadata": {},
   "source": [
    "- удалось улучшить MAE в сранении с бэйзлайном самой модели и в целом\n",
    "- однако процент overfitting довольно большой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8bbc54",
   "metadata": {},
   "source": [
    "## 6. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f0ef06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cat(trial, X, y, N_FOLDS, random_state, cat_feat):\n",
    "    cat_params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [1148]),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.03993043117456255]),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5,1.0),\n",
    "        'l2_leaf_reg': trial.suggest_uniform('l2_leaf_reg', 1e-5, 1e2),\n",
    "        'random_strength': trial.suggest_uniform('random_strength', 10, 50),\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS', 'No']),\n",
    "        'border_count': trial.suggest_categorical('border_count', [128, 254]),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'od_wait': trial.suggest_int('od_wait', 500, 2000),\n",
    "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 15),\n",
    "        'loss_function': trial.suggest_categorical('loss_function', ['MAE']),\n",
    "        'use_best_model': trial.suggest_categorical('use_best_model', [True]),\n",
    "        'eval_metric': trial.suggest_categorical('eval_metric', ['MAE']),\n",
    "        'random_state': trial.suggest_categorical('random_state', [random_state])\n",
    "    }\n",
    "\n",
    "    if cat_params['bootstrap_type'] == 'Bayesian':\n",
    "        cat_params['bagging_temperature'] = trial.suggest_float(\n",
    "            'bagging_temperature', 0, 100)\n",
    "    elif cat_params['bootstrap_type'] == 'Bernoulli':\n",
    "        cat_params['subsample'] = trial.suggest_float(\n",
    "            'subsample', 0.1, 1, log=True)\n",
    "\n",
    "    cv = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_feat)\n",
    "        eval_data = Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
    "\n",
    "        model = CatBoostRegressor(**cat_params)\n",
    "        model.fit(train_data,\n",
    "                  eval_set=eval_data,\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = mean_absolute_error(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "476a045a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ba416f9b924ec2bc40df08e45f07be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_cat = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    pruner=optuna.pruners.SuccessiveHalvingPruner(),\n",
    "    study_name='Cat_00')\n",
    "func = lambda trial: objective_cat(trial,\n",
    "                                   X_train_ct,\n",
    "                                   y_train_ct,\n",
    "                                   N_FOLDS=N_FOLDS,\n",
    "                                   random_state=RAND,\n",
    "                                   cat_feat=cat_features)\n",
    "study_cat.optimize(func, n_trials=2, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f682aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1148,\n",
       " 'learning_rate': 0.03993043117456255,\n",
       " 'max_depth': 8,\n",
       " 'colsample_bylevel': 0.7825642278921418,\n",
       " 'l2_leaf_reg': 11.435953759453188,\n",
       " 'random_strength': 33.22518563290565,\n",
       " 'bootstrap_type': 'No',\n",
       " 'border_count': 128,\n",
       " 'grow_policy': 'Lossguide',\n",
       " 'od_wait': 739,\n",
       " 'leaf_estimation_iterations': 2,\n",
       " 'loss_function': 'MAE',\n",
       " 'use_best_model': True,\n",
       " 'eval_metric': 'MAE',\n",
       " 'random_state': 10}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смотрим на параметры\n",
    "study_cat.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d36f44ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>MPE_%</th>\n",
       "      <th>MAPE_%</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression_baseline</td>\n",
       "      <td>8.347072</td>\n",
       "      <td>156.858720</td>\n",
       "      <td>12.524325</td>\n",
       "      <td>0.455343</td>\n",
       "      <td>0.451267</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>34.324438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisonTreeRegressor_baseline</td>\n",
       "      <td>10.133774</td>\n",
       "      <td>228.179589</td>\n",
       "      <td>15.105614</td>\n",
       "      <td>0.607437</td>\n",
       "      <td>0.201768</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>41.671629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor_baseline</td>\n",
       "      <td>8.258138</td>\n",
       "      <td>176.019952</td>\n",
       "      <td>13.267251</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.384236</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>33.958726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_baseline</td>\n",
       "      <td>7.173608</td>\n",
       "      <td>121.679612</td>\n",
       "      <td>11.030848</td>\n",
       "      <td>0.398242</td>\n",
       "      <td>0.574333</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>29.498972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_baseline</td>\n",
       "      <td>7.120787</td>\n",
       "      <td>122.711309</td>\n",
       "      <td>11.077514</td>\n",
       "      <td>0.393043</td>\n",
       "      <td>0.573203</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>29.304653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_baseline</td>\n",
       "      <td>6.453979</td>\n",
       "      <td>99.260909</td>\n",
       "      <td>9.962977</td>\n",
       "      <td>0.359331</td>\n",
       "      <td>0.654765</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>26.560497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_Optuna</td>\n",
       "      <td>6.443470</td>\n",
       "      <td>102.503548</td>\n",
       "      <td>10.124404</td>\n",
       "      <td>0.364783</td>\n",
       "      <td>0.643487</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>26.517247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_Optuna</td>\n",
       "      <td>6.445009</td>\n",
       "      <td>97.164593</td>\n",
       "      <td>9.857210</td>\n",
       "      <td>0.366083</td>\n",
       "      <td>0.662056</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>26.523582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model        MAE         MSE       RMSE     RMSLE  \\\n",
       "0       LinearRegression_baseline   8.347072  156.858720  12.524325  0.455343   \n",
       "0   DecisonTreeRegressor_baseline  10.133774  228.179589  15.105614  0.607437   \n",
       "0  RandomForestRegressor_baseline   8.258138  176.019952  13.267251  0.476677   \n",
       "0                XGBoost_baseline   7.173608  121.679612  11.030848  0.398242   \n",
       "0               LightGBM_baseline   7.120787  122.711309  11.077514  0.393043   \n",
       "0               CatBoost_baseline   6.453979   99.260909   9.962977  0.359331   \n",
       "0                 LightGBM_Optuna   6.443470  102.503548  10.124404  0.364783   \n",
       "0                 CatBoost_Optuna   6.445009   97.164593   9.857210  0.366083   \n",
       "\n",
       "   R2 adjusted  MPE_%  MAPE_%     WAPE_%  \n",
       "0     0.451267   -inf     inf  34.324438  \n",
       "0     0.201768   -inf     inf  41.671629  \n",
       "0     0.384236   -inf     inf  33.958726  \n",
       "0     0.574333   -inf     inf  29.498972  \n",
       "0     0.573203   -inf     inf  29.304653  \n",
       "0     0.654765   -inf     inf  26.560497  \n",
       "0     0.643487   -inf     inf  26.517247  \n",
       "0     0.662056   -inf     inf  26.523582  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_opt = CatBoostRegressor(**study_cat.best_params)\n",
    "cb_opt.fit(X_ct,\n",
    "           y_ct,\n",
    "           cat_features=cat_features,\n",
    "           eval_set=eval_ct,\n",
    "           verbose=False,\n",
    "           early_stopping_rounds=100)\n",
    "\n",
    "y_pred = cb_opt.predict(X_test_ct)\n",
    "y_pred_exp = np.exp(y_pred) - 1\n",
    "\n",
    "\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics_regression(y_test=y_test_ct_exp,\n",
    "                           y_pred=y_pred_exp,\n",
    "                           X_test=X_test_ct,\n",
    "                           name='CatBoost_Optuna'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c2bfe5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error train: 5.859\n",
      "Mean absolute error test: 6.445\n",
      "delta = 9.1 %\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(cb_opt,\n",
    "                  X_ct,\n",
    "                  y_ct_exp,\n",
    "                  X_test_ct,\n",
    "                  y_test_ct_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a13daa",
   "metadata": {},
   "source": [
    "- тюнинг CatBoost привел к чуть более плохой метрике\n",
    "- но зато переобучение значительно ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee07eb4",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458659d6",
   "metadata": {},
   "source": [
    "Возьмем комбинацию нескольких LightGBM и CatBoost, так как среди сложных моделей в них самые низкие метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec14da",
   "metadata": {},
   "source": [
    "## LGBM tune 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65bd9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial, X, y, N_FOLDS, random_state=10):\n",
    "    lgb_params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [2983]),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.08256755427823]),        \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 1000, step=20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 15),\n",
    "        # борьба с переобучением\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 0, 100),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 0, 100),\n",
    "        'min_split_gain': trial.suggest_int('min_split_gain', 0, 20),\n",
    "        # доля объектов при обучении в дереве\n",
    "        'subsample': trial.suggest_float('bagging_fraction', 0.2, 1.0),\n",
    "        'subsample_freq': trial.suggest_categorical('bagging_freq', [1]),\n",
    "        # доля признаков при обучении в дереве\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
    "        # константы\n",
    "        'objective': trial.suggest_categorical('objective', ['mae']),\n",
    "        'random_state': trial.suggest_categorical('random_state', [random_state])\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=N_FOLDS, shuffle=True)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(\n",
    "           trial, metric='l1')\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  eval_metric='mae',\n",
    "                  callbacks=[pruning_callback],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = mean_absolute_error(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a46b5a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef34718a396c4fb99ae88cfe46ee7803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_lgbm_01 = optuna.create_study(direction='minimize', study_name='LGB_01')\n",
    "func = lambda trial: objective_lgbm(\n",
    "    trial, X_train_ct, y_train_ct, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_lgbm_01.optimize(func, n_trials=5, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50e00794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 2983,\n",
       " 'learning_rate': 0.08256755427823,\n",
       " 'num_leaves': 420,\n",
       " 'max_depth': 13,\n",
       " 'reg_alpha': 20,\n",
       " 'reg_lambda': 45,\n",
       " 'min_split_gain': 20,\n",
       " 'bagging_fraction': 0.9763861100885414,\n",
       " 'bagging_freq': 1,\n",
       " 'colsample_bytree': 0.9089776601002373,\n",
       " 'objective': 'mae',\n",
       " 'random_state': 10}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смотрим на параметры\n",
    "study_lgbm_01.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "da5b8ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9763861100885414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9763861100885414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 1 MAE SCORE 6.906\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9763861100885414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9763861100885414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 2 MAE SCORE 6.852\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9763861100885414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9763861100885414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 3 MAE SCORE 6.845\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9763861100885414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9763861100885414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 4 MAE SCORE 6.992\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9763861100885414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9763861100885414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "meta_X = pd.DataFrame()\n",
    "meta_X_test = pd.DataFrame()\n",
    "    \n",
    "pred_val = []\n",
    "    \n",
    "folds = KFold(n_splits=N_FOLDS, random_state=RAND, shuffle=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(folds.split(X_train_ct, y_train_ct)):\n",
    "    X_train_, X_val = X_train_ct.iloc[train_index], X_train_ct.iloc[test_index]\n",
    "    y_train_, y_val = y_train_ct.iloc[train_index], y_train_ct.iloc[test_index]\n",
    "    \n",
    "    y_val_exp = np.exp(y_val) - 1\n",
    "\n",
    "    model = LGBMRegressor(**study_lgbm_01.best_params)\n",
    "\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric='mae',\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred_val_exp = np.exp(y_pred_val) - 1\n",
    "\n",
    "    print('Fold:', fold + 1,\n",
    "          'MAE SCORE %.3f' % mean_absolute_error(y_val_exp, y_pred_val_exp))\n",
    "    print('---')\n",
    "\n",
    "    pred_val.append(y_pred_val_exp)\n",
    "    \n",
    "model.fit(X_ct,\n",
    "          y_ct,\n",
    "          eval_set=eval_ct,\n",
    "          eval_metric='mae',\n",
    "          early_stopping_rounds=100,\n",
    "          verbose=0)\n",
    "\n",
    "meta_X['lgbm_01'] = np.concatenate(pred_val)\n",
    "meta_X_test['lgbm_01'] = np.exp(model.predict(X_test_ct)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b06b1cd",
   "metadata": {},
   "source": [
    "## LGBM tune 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c98b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial, X, y, N_FOLDS, random_state=10):\n",
    "    lgb_params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [3902]),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.03396563179672953]),        \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 1000, step=20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 15),\n",
    "        # борьба с переобучением\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 0, 100),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 0, 100),\n",
    "        'min_split_gain': trial.suggest_int('min_split_gain', 0, 20),\n",
    "        # доля объектов при обучении в дереве\n",
    "        'subsample': trial.suggest_float('bagging_fraction', 0.2, 1.0),\n",
    "        'subsample_freq': trial.suggest_categorical('bagging_freq', [1]),\n",
    "        # доля признаков при обучении в дереве\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
    "        # константы\n",
    "        'objective': trial.suggest_categorical('objective', ['mae']),\n",
    "        'random_state': trial.suggest_categorical('random_state', [random_state])\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=N_FOLDS, shuffle=True)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(\n",
    "           trial, metric='l1')\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  eval_metric='mae',\n",
    "                  callbacks=[pruning_callback],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = mean_absolute_error(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "204e2300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3469c1790aca4682b22b6faf31424f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_lgbm_02 = optuna.create_study(direction='minimize', study_name='LGB_02')\n",
    "func = lambda trial: objective_lgbm(\n",
    "    trial, X_train_ct, y_train_ct, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_lgbm_02.optimize(func, n_trials=5, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bcd525c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 3902,\n",
       " 'learning_rate': 0.03396563179672953,\n",
       " 'num_leaves': 620,\n",
       " 'max_depth': 11,\n",
       " 'reg_alpha': 14,\n",
       " 'reg_lambda': 99,\n",
       " 'min_split_gain': 4,\n",
       " 'bagging_fraction': 0.9669453988823131,\n",
       " 'bagging_freq': 1,\n",
       " 'colsample_bytree': 0.49260769967158996,\n",
       " 'objective': 'mae',\n",
       " 'random_state': 10}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смотрим на параметры\n",
    "study_lgbm_02.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e12de003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9669453988823131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9669453988823131\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 1 MAE SCORE 6.595\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9669453988823131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9669453988823131\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 2 MAE SCORE 6.542\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9669453988823131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9669453988823131\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 3 MAE SCORE 6.562\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9669453988823131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9669453988823131\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 4 MAE SCORE 6.675\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9669453988823131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9669453988823131\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "pred_val = []\n",
    "    \n",
    "folds = KFold(n_splits=N_FOLDS, random_state=RAND, shuffle=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(folds.split(X_train_ct, y_train_ct)):\n",
    "    X_train_, X_val = X_train_ct.iloc[train_index], X_train_ct.iloc[test_index]\n",
    "    y_train_, y_val = y_train_ct.iloc[train_index], y_train_ct.iloc[test_index]\n",
    "    \n",
    "    y_val_exp = np.exp(y_val) - 1\n",
    "\n",
    "    model = LGBMRegressor(**study_lgbm_02.best_params)\n",
    "\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric='mae',\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred_val_exp = np.exp(y_pred_val) - 1\n",
    "\n",
    "    print('Fold:', fold + 1,\n",
    "          'MAE SCORE %.3f' % mean_absolute_error(y_val_exp, y_pred_val_exp))\n",
    "    print('---')\n",
    "\n",
    "    pred_val.append(y_pred_val_exp)\n",
    "    \n",
    "model.fit(X_ct,\n",
    "          y_ct,\n",
    "          eval_set=eval_ct,\n",
    "          eval_metric='mae',\n",
    "          early_stopping_rounds=100,\n",
    "          verbose=0)\n",
    "\n",
    "meta_X['lgbm_02'] = np.concatenate(pred_val)\n",
    "meta_X_test['lgbm_02'] = np.exp(model.predict(X_test_ct)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b181716",
   "metadata": {},
   "source": [
    "## LGBM tune 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09ff2fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial, X, y, N_FOLDS, random_state=10):\n",
    "    lgb_params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [2482]),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.05380382705463601]),        \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 1000, step=20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 15),\n",
    "        # борьба с переобучением\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 0, 100),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 0, 100),\n",
    "        'min_split_gain': trial.suggest_int('min_split_gain', 0, 20),\n",
    "        # доля объектов при обучении в дереве\n",
    "        'subsample': trial.suggest_float('bagging_fraction', 0.2, 1.0),\n",
    "        'subsample_freq': trial.suggest_categorical('bagging_freq', [1]),\n",
    "        # доля признаков при обучении в дереве\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
    "        # константы\n",
    "        'objective': trial.suggest_categorical('objective', ['mae']),\n",
    "        'random_state': trial.suggest_categorical('random_state', [random_state])\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=N_FOLDS, shuffle=True)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(\n",
    "           trial, metric='l1')\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  eval_metric='mae',\n",
    "                  callbacks=[pruning_callback],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = mean_absolute_error(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb9550a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03d1ad076cb4de9a2092dcfe2985b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_lgbm_03 = optuna.create_study(direction='minimize', study_name='LGB_03')\n",
    "func = lambda trial: objective_lgbm(\n",
    "    trial, X_train_ct, y_train_ct, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_lgbm_03.optimize(func, n_trials=5, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb6f2e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 2482,\n",
       " 'learning_rate': 0.05380382705463601,\n",
       " 'num_leaves': 700,\n",
       " 'max_depth': 15,\n",
       " 'reg_alpha': 10,\n",
       " 'reg_lambda': 96,\n",
       " 'min_split_gain': 1,\n",
       " 'bagging_fraction': 0.9693332848337597,\n",
       " 'bagging_freq': 1,\n",
       " 'colsample_bytree': 0.5004742141096672,\n",
       " 'objective': 'mae',\n",
       " 'random_state': 10}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смотрим на параметры\n",
    "study_lgbm_03.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a6bb7f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9693332848337597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9693332848337597\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 1 MAE SCORE 6.236\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9693332848337597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9693332848337597\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 2 MAE SCORE 6.194\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9693332848337597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9693332848337597\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 3 MAE SCORE 6.215\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9693332848337597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9693332848337597\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 4 MAE SCORE 6.306\n",
      "---\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9693332848337597, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9693332848337597\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "pred_val = []\n",
    "    \n",
    "folds = KFold(n_splits=N_FOLDS, random_state=RAND, shuffle=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(folds.split(X_train_ct, y_train_ct)):\n",
    "    X_train_, X_val = X_train_ct.iloc[train_index], X_train_ct.iloc[test_index]\n",
    "    y_train_, y_val = y_train_ct.iloc[train_index], y_train_ct.iloc[test_index]\n",
    "    \n",
    "    y_val_exp = np.exp(y_val) - 1\n",
    "\n",
    "    model = LGBMRegressor(**study_lgbm_03.best_params)\n",
    "\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric='mae',\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred_val_exp = np.exp(y_pred_val) - 1\n",
    "\n",
    "    print('Fold:', fold + 1,\n",
    "          'MAE SCORE %.3f' % mean_absolute_error(y_val_exp, y_pred_val_exp))\n",
    "    print('---')\n",
    "\n",
    "    pred_val.append(y_pred_val_exp)\n",
    "    \n",
    "model.fit(X_ct,\n",
    "          y_ct,\n",
    "          eval_set=eval_ct,\n",
    "          eval_metric='mae',\n",
    "          early_stopping_rounds=100,\n",
    "          verbose=0)\n",
    "\n",
    "meta_X['lgbm_03'] = np.concatenate(pred_val)\n",
    "meta_X_test['lgbm_03'] = np.exp(model.predict(X_test_ct)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416ec16",
   "metadata": {},
   "source": [
    "## CatBoost from tunining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e984d7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1148,\n",
       " 'learning_rate': 0.03993043117456255,\n",
       " 'max_depth': 8,\n",
       " 'colsample_bylevel': 0.7825642278921418,\n",
       " 'l2_leaf_reg': 11.435953759453188,\n",
       " 'random_strength': 33.22518563290565,\n",
       " 'bootstrap_type': 'No',\n",
       " 'border_count': 128,\n",
       " 'grow_policy': 'Lossguide',\n",
       " 'od_wait': 739,\n",
       " 'leaf_estimation_iterations': 2,\n",
       " 'loss_function': 'MAE',\n",
       " 'use_best_model': True,\n",
       " 'eval_metric': 'MAE',\n",
       " 'random_state': 10}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_cat.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aeb2f175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 MAE SCORE 6.277\n",
      "---\n",
      "Fold: 2 MAE SCORE 6.248\n",
      "---\n",
      "Fold: 3 MAE SCORE 6.266\n",
      "---\n",
      "Fold: 4 MAE SCORE 6.349\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "pred_val = []\n",
    "    \n",
    "folds = KFold(n_splits=N_FOLDS, random_state=RAND, shuffle=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(folds.split(X_train_ct, y_train_ct)):\n",
    "    X_train_, X_val = X_train_ct.iloc[train_index], X_train_ct.iloc[test_index]\n",
    "    y_train_, y_val = y_train_ct.iloc[train_index], y_train_ct.iloc[test_index]\n",
    "    \n",
    "    y_val_exp = np.exp(y_val) - 1\n",
    "\n",
    "    model = CatBoostRegressor(**study_cat.best_params)\n",
    "\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              cat_features=cat_features,\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred_val_exp = np.exp(y_pred_val) - 1\n",
    "\n",
    "    print('Fold:', fold + 1,\n",
    "          'MAE SCORE %.3f' % mean_absolute_error(y_val_exp, y_pred_val_exp))\n",
    "    print('---')\n",
    "\n",
    "    pred_val.append(y_pred_val_exp)\n",
    "    \n",
    "model.fit(X_ct,\n",
    "          y_ct,\n",
    "          cat_features=cat_features,\n",
    "          eval_set=eval_ct,\n",
    "          verbose=False,\n",
    "          early_stopping_rounds=100)\n",
    "\n",
    "meta_X['cb_tune'] = np.concatenate(pred_val)\n",
    "meta_X_test['cb_tune'] = np.exp(model.predict(X_test_ct)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f23eb91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm_01</th>\n",
       "      <th>lgbm_02</th>\n",
       "      <th>lgbm_03</th>\n",
       "      <th>cb_tune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.718809</td>\n",
       "      <td>24.115703</td>\n",
       "      <td>22.475911</td>\n",
       "      <td>22.874065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.907353</td>\n",
       "      <td>19.620355</td>\n",
       "      <td>19.833160</td>\n",
       "      <td>20.026198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.943912</td>\n",
       "      <td>19.535152</td>\n",
       "      <td>18.498824</td>\n",
       "      <td>18.630465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.065007</td>\n",
       "      <td>19.768570</td>\n",
       "      <td>18.409541</td>\n",
       "      <td>17.096548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.417453</td>\n",
       "      <td>9.867613</td>\n",
       "      <td>9.883602</td>\n",
       "      <td>8.729491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lgbm_01    lgbm_02    lgbm_03    cb_tune\n",
       "0  24.718809  24.115703  22.475911  22.874065\n",
       "1  20.907353  19.620355  19.833160  20.026198\n",
       "2  18.943912  19.535152  18.498824  18.630465\n",
       "3  20.065007  19.768570  18.409541  17.096548\n",
       "4   9.417453   9.867613   9.883602   8.729491"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "30e900b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm_01</th>\n",
       "      <th>lgbm_02</th>\n",
       "      <th>lgbm_03</th>\n",
       "      <th>cb_tune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.245693</td>\n",
       "      <td>7.571461</td>\n",
       "      <td>7.665905</td>\n",
       "      <td>7.064705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.537094</td>\n",
       "      <td>69.968293</td>\n",
       "      <td>67.352959</td>\n",
       "      <td>73.142172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.382781</td>\n",
       "      <td>11.658344</td>\n",
       "      <td>11.257861</td>\n",
       "      <td>12.236397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.425789</td>\n",
       "      <td>17.956439</td>\n",
       "      <td>16.970769</td>\n",
       "      <td>18.792646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.455602</td>\n",
       "      <td>24.243460</td>\n",
       "      <td>24.436538</td>\n",
       "      <td>33.370898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lgbm_01    lgbm_02    lgbm_03    cb_tune\n",
       "0   8.245693   7.571461   7.665905   7.064705\n",
       "1  68.537094  69.968293  67.352959  73.142172\n",
       "2   9.382781  11.658344  11.257861  12.236397\n",
       "3  17.425789  17.956439  16.970769  18.792646\n",
       "4  25.455602  24.243460  24.436538  33.370898"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d0c525",
   "metadata": {},
   "source": [
    "## Final meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ee410ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_model = LinearRegression()\n",
    "stack_model.fit(meta_X, y_train_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "49fe9c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>MPE_%</th>\n",
       "      <th>MAPE_%</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression_baseline</td>\n",
       "      <td>8.347072</td>\n",
       "      <td>156.858720</td>\n",
       "      <td>12.524325</td>\n",
       "      <td>0.455343</td>\n",
       "      <td>0.451267</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>34.324438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisonTreeRegressor_baseline</td>\n",
       "      <td>10.133774</td>\n",
       "      <td>228.179589</td>\n",
       "      <td>15.105614</td>\n",
       "      <td>0.607437</td>\n",
       "      <td>0.201768</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>41.671629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor_baseline</td>\n",
       "      <td>8.258138</td>\n",
       "      <td>176.019952</td>\n",
       "      <td>13.267251</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.384236</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>33.958726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_baseline</td>\n",
       "      <td>7.173608</td>\n",
       "      <td>121.679612</td>\n",
       "      <td>11.030848</td>\n",
       "      <td>0.398242</td>\n",
       "      <td>0.574333</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>29.498972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_baseline</td>\n",
       "      <td>7.120787</td>\n",
       "      <td>122.711309</td>\n",
       "      <td>11.077514</td>\n",
       "      <td>0.393043</td>\n",
       "      <td>0.573203</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>29.304653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_baseline</td>\n",
       "      <td>6.453979</td>\n",
       "      <td>99.260909</td>\n",
       "      <td>9.962977</td>\n",
       "      <td>0.359331</td>\n",
       "      <td>0.654765</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>26.560497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_Optuna</td>\n",
       "      <td>6.443470</td>\n",
       "      <td>102.503548</td>\n",
       "      <td>10.124404</td>\n",
       "      <td>0.364783</td>\n",
       "      <td>0.643487</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>26.517247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_Optuna</td>\n",
       "      <td>6.445009</td>\n",
       "      <td>97.164593</td>\n",
       "      <td>9.857210</td>\n",
       "      <td>0.366083</td>\n",
       "      <td>0.662056</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>26.523582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking_hand_tune</td>\n",
       "      <td>12.107403</td>\n",
       "      <td>310.438572</td>\n",
       "      <td>17.619267</td>\n",
       "      <td>0.653396</td>\n",
       "      <td>-0.079723</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>49.826410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model        MAE         MSE       RMSE     RMSLE  \\\n",
       "0       LinearRegression_baseline   8.347072  156.858720  12.524325  0.455343   \n",
       "0   DecisonTreeRegressor_baseline  10.133774  228.179589  15.105614  0.607437   \n",
       "0  RandomForestRegressor_baseline   8.258138  176.019952  13.267251  0.476677   \n",
       "0                XGBoost_baseline   7.173608  121.679612  11.030848  0.398242   \n",
       "0               LightGBM_baseline   7.120787  122.711309  11.077514  0.393043   \n",
       "0               CatBoost_baseline   6.453979   99.260909   9.962977  0.359331   \n",
       "0                 LightGBM_Optuna   6.443470  102.503548  10.124404  0.364783   \n",
       "0                 CatBoost_Optuna   6.445009   97.164593   9.857210  0.366083   \n",
       "0              Stacking_hand_tune  12.107403  310.438572  17.619267  0.653396   \n",
       "\n",
       "   R2 adjusted  MPE_%  MAPE_%     WAPE_%  \n",
       "0     0.451267   -inf     inf  34.324438  \n",
       "0     0.201768   -inf     inf  41.671629  \n",
       "0     0.384236   -inf     inf  33.958726  \n",
       "0     0.574333   -inf     inf  29.498972  \n",
       "0     0.573203   -inf     inf  29.304653  \n",
       "0     0.654765   -inf     inf  26.560497  \n",
       "0     0.643487   -inf     inf  26.517247  \n",
       "0     0.662056   -inf     inf  26.523582  \n",
       "0    -0.079723   -inf     inf  49.826410  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stack_model.predict(meta_X_test)\n",
    "y_pred_exp = np.exp(y_pred) - 1\n",
    "\n",
    "metrics = metrics.append(\n",
    "    get_metrics_regression(y_test_ct_exp, y_pred_exp, X_test_ct,\n",
    "                           name='Stacking_hand_tune'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "efdc1352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error train: 12.033\n",
      "Mean absolute error test: 12.107\n",
      "delta = 0.6 %\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(stack_model,\n",
    "                  meta_X,\n",
    "                  y_train_ct_exp,\n",
    "                  meta_X_test,\n",
    "                  y_test_ct_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1ee19",
   "metadata": {},
   "source": [
    "- MAE заметно ухудшилась\n",
    "- однако переобучение минимальное, что особенно важно для градиентных бустингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dacf8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним итоговую таблицу с метриками\n",
    "metrics.to_csv(r'C:\\Users\\main6\\OneDrive\\Документы\\jupyter\\Pet_pro\\data\\final_metrics.csv',\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "029eeae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним переменные для анализа важных признаков в конце\n",
    "with open (r'C:\\Users\\main6\\OneDrive\\Документы\\jupyter\\Pet_pro\\models\\test_ct.pkl', \n",
    "           'wb') as f:\n",
    "    pickle.dump((X_test_ct, y_test_ct), f)\n",
    "\n",
    "with open(r'C:\\Users\\main6\\OneDrive\\Документы\\jupyter\\Pet_pro\\models\\models.pkl',\n",
    "          'wb') as f:\n",
    "    pickle.dump((lgbm_opt, cb_opt), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d332e15",
   "metadata": {},
   "source": [
    "#### Общие выводы:\n",
    "\n",
    "- для поиска наилучших гиперпараметров была использована библиотека Optunf\n",
    "- в результате настройки были получены очень низкие показатели MAE\n",
    "- стэкинг позваляет не переобучаться\n",
    "- лучший результат на LightGBM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
